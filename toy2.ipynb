{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4599969-9bc6-42e8-bb35-fc0220cbd172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Phase 1: Personas ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>econ</th>\n",
       "      <th>social</th>\n",
       "      <th>tech</th>\n",
       "      <th>governance</th>\n",
       "      <th>comm_style</th>\n",
       "      <th>background</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vestra</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>narrative</td>\n",
       "      <td>Urban Planner, Activist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lytje</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>data-driven</td>\n",
       "      <td>Researcher, Journalist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mentor</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>pragmatic</td>\n",
       "      <td>Entrepreneur, Educator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gert</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>diplomatic</td>\n",
       "      <td>Activist, Community Organizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xandros</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>legalistic</td>\n",
       "      <td>Investor, Politician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Heike</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>data-driven</td>\n",
       "      <td>Researcher, Academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kai</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>pugilistic</td>\n",
       "      <td>Activist, Community Organizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Walter</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>pragmatic</td>\n",
       "      <td>Investor, Politician</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  econ  social  tech governance   comm_style  \\\n",
       "0   Vestra     1       2  None       None    narrative   \n",
       "1    Lytje     1       2  None       None  data-driven   \n",
       "2   Mentor     1       2  None       None    pragmatic   \n",
       "3     Gert     1       2  None       None   diplomatic   \n",
       "4  Xandros     1       2  None       None   legalistic   \n",
       "5    Heike     1       2  None       None  data-driven   \n",
       "6      Kai     1       2  None       None   pugilistic   \n",
       "7   Walter     1       2  None       None    pragmatic   \n",
       "\n",
       "                      background  \n",
       "0        Urban Planner, Activist  \n",
       "1         Researcher, Journalist  \n",
       "2         Entrepreneur, Educator  \n",
       "3  Activist, Community Organizer  \n",
       "4           Investor, Politician  \n",
       "5           Researcher, Academic  \n",
       "6  Activist, Community Organizer  \n",
       "7           Investor, Politician  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Phase 2: Topic & Levers ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>phase_plan</th>\n",
       "      <th>prompt</th>\n",
       "      <th>disagreement_levers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>congestion pricing</td>\n",
       "      <td>[brainstorm, triage, focused_deliberation, ref...</td>\n",
       "      <td>Neutral question forcing trade-offs (who pays,...</td>\n",
       "      <td>[cost allocation, liberty vs safety, equity vs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                topic                                         phase_plan  \\\n",
       "0  congestion pricing  [brainstorm, triage, focused_deliberation, ref...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Neutral question forcing trade-offs (who pays,...   \n",
       "\n",
       "                                 disagreement_levers  \n",
       "0  [cost allocation, liberty vs safety, equity vs...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Phase 3: Brainstorm (one-liners) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vestra</td>\n",
       "      <td>What is a fair and efficient way to implement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lytje</td>\n",
       "      <td>The optimal congestion pricing solution would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mentor</td>\n",
       "      <td>\"By taxing luxury vehicles, local governments ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gert</td>\n",
       "      <td>Implementing congestion pricing in a way that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xandros</td>\n",
       "      <td>Local governments should set user fees based o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Heike</td>\n",
       "      <td>The optimal congestion pricing solution should...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kai</td>\n",
       "      <td>Heike: Implementing congestion pricing with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Walter</td>\n",
       "      <td>Kai's sentence: \"While implementing congestion...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name                                              reply\n",
       "0   Vestra  What is a fair and efficient way to implement ...\n",
       "1    Lytje  The optimal congestion pricing solution would ...\n",
       "2   Mentor  \"By taxing luxury vehicles, local governments ...\n",
       "3     Gert  Implementing congestion pricing in a way that ...\n",
       "4  Xandros  Local governments should set user fees based o...\n",
       "5    Heike  The optimal congestion pricing solution should...\n",
       "6      Kai  Heike: Implementing congestion pricing with a ...\n",
       "7   Walter  Kai's sentence: \"While implementing congestion..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Phase 4: Triage (propositions) ===\n"
     ]
    },
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPConnectionPool(host='localhost', port=1234): Read timed out. (read timeout=60)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1429\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    719\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[31mTimeoutError\u001b[39m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mReadTimeoutError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/urllib3/connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/urllib3/util/retry.py:474\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/urllib3/util/util.py:39\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/urllib3/connectionpool.py:367\u001b[39m, in \u001b[36mHTTPConnectionPool._raise_timeout\u001b[39m\u001b[34m(self, err, url, timeout_value)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m, url, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    369\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[31mReadTimeoutError\u001b[39m: HTTPConnectionPool(host='localhost', port=1234): Read timed out. (read timeout=60)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 450\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDone.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    449\u001b[39m \u001b[38;5;66;03m# --------------------------- Run ------------------------------------\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 419\u001b[39m, in \u001b[36mrun_pipeline\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    416\u001b[39m responses = run_brainstorm(personas, topic, prompt, levers)\n\u001b[32m    418\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Phase 4: Triage (propositions) ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m props = \u001b[43mextract_diverse_propositions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK_PROPS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Phase 5: Stance labeling ([-2..+2]) ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    422\u001b[39m persona_names = [p[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m personas]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 236\u001b[39m, in \u001b[36mextract_diverse_propositions\u001b[39m\u001b[34m(responses, k)\u001b[39m\n\u001b[32m    224\u001b[39m joined = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join([\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m responses.items()])\n\u001b[32m    225\u001b[39m user = {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m:textwrap.dedent(\u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[33mFrom these one-sentence replies:\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[33m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjoined\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    234\u001b[39m \u001b[33m\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33mpropositions_all\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m:[...], \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpropositions\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m:[...]\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m).strip()}\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m data = \u001b[43mllm_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTEMPERATURE_GEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTOP_P_GEN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    237\u001b[39m props = data.get(\u001b[33m\"\u001b[39m\u001b[33mpropositions\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m data.get(\u001b[33m\"\u001b[39m\u001b[33mpropositions_all\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    238\u001b[39m \u001b[38;5;66;03m# Light dedup & MMR safety net\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 91\u001b[39m, in \u001b[36mllm_json\u001b[39m\u001b[34m(messages, temperature, top_p)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mllm_json\u001b[39m(messages: List[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]], temperature: \u001b[38;5;28mfloat\u001b[39m, top_p: \u001b[38;5;28mfloat\u001b[39m) -> Any:\n\u001b[32m     90\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call LLM and parse strict JSON; one retry with 'STRICT JSON only'.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     out = \u001b[43mcall_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     93\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m parse_json_strict(out)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mcall_llm\u001b[39m\u001b[34m(messages, temperature, top_p)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Call the OpenAI-compatible Chat Completions API (single endpoint only).\"\"\"\u001b[39;00m\n\u001b[32m     44\u001b[39m payload = {\n\u001b[32m     45\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: LLM_MODEL,\n\u001b[32m     46\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     51\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m resp = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mLLM_ENDPOINT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mContent-Type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mREQUEST_TIMEOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m resp.raise_for_status()\n\u001b[32m     59\u001b[39m data = resp.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/requests/api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/requests/adapters.py:713\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[32m--> \u001b[39m\u001b[32m713\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request=request)\n\u001b[32m    714\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[32m    715\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request=request)\n",
      "\u001b[31mReadTimeout\u001b[39m: HTTPConnectionPool(host='localhost', port=1234): Read timed out. (read timeout=60)"
     ]
    }
   ],
   "source": [
    "# TinyCongress — KISS multi‑phase deliberation demo (Jupyter-friendly)\n",
    "# Phases:\n",
    "#   1) Persona generation (diverse ideology axes)\n",
    "#   2) Topic + disagreement levers\n",
    "#   3) Brainstorm (sequential, one-sentence replies)\n",
    "#   4) Triage (canonical propositions; diversity-first)\n",
    "#   5) Stance labeling ([-2..+2], rubric & rarity rule)\n",
    "#   6) Clustering + maps (tables + charts)\n",
    "#   7) Focused deliberation (LLM-bridging statements)\n",
    "#   8) Reflection & decision (rank bridging & polarizing)\n",
    "\n",
    "import json, time, random, re, textwrap\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------- Configuration ---------------------------\n",
    "LLM_ENDPOINT = \"http://localhost:1234/v1/chat/completions\"  # your local server\n",
    "LLM_MODEL    = \"llama-3.2-1b-instruct\"                      # use this for ALL prompts\n",
    "TEMPERATURE_GEN = 0.75                                      # for generative prompts (personas, replies, text)\n",
    "TOP_P_GEN       = 0.9\n",
    "TEMPERATURE_LABEL = 0.1                                     # for stance labeling (deterministic)\n",
    "TOP_P_LABEL       = 0.9\n",
    "\n",
    "RANDOM_SEED   = 42\n",
    "N_PERSONAS    = 12\n",
    "K_PROPS       = 12\n",
    "N_CLUSTERS    = 2\n",
    "REQUEST_TIMEOUT = 60\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# --------------------------- LLM Client ------------------------------\n",
    "def call_llm(messages: List[Dict[str, str]], temperature: float, top_p: float) -> str:\n",
    "    \"\"\"Call the OpenAI-compatible Chat Completions API (single endpoint only).\"\"\"\n",
    "    payload = {\n",
    "        \"model\": LLM_MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": float(temperature),\n",
    "        \"top_p\": float(top_p),\n",
    "        \"max_tokens\": -1,\n",
    "        \"stream\": False,\n",
    "    }\n",
    "    resp = requests.post(\n",
    "        LLM_ENDPOINT,\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "        data=json.dumps(payload),\n",
    "        timeout=REQUEST_TIMEOUT,\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    content = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return content\n",
    "\n",
    "def parse_json_strict(content: str) -> Any:\n",
    "    \"\"\"Parse JSON; try fenced blocks and raw_decode if needed.\"\"\"\n",
    "    if content is None:\n",
    "        raise ValueError(\"LLM returned None\")\n",
    "    txt = content.strip()\n",
    "    # strip accidental <think> tags\n",
    "    txt = re.sub(r\"</?think>\", \"\", txt, flags=re.IGNORECASE).strip()\n",
    "    # 1) direct\n",
    "    try:\n",
    "        return json.loads(txt)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # 2) fenced code\n",
    "    m = re.search(r\"```(?:json)?\\s*(.*?)\\s*```\", txt, flags=re.DOTALL|re.IGNORECASE)\n",
    "    if m:\n",
    "        return json.loads(m.group(1))\n",
    "    # 3) raw decode from first { or [\n",
    "    dec = json.JSONDecoder()\n",
    "    for match in re.finditer(r\"[\\[{]\", txt):\n",
    "        try:\n",
    "            obj, _ = dec.raw_decode(txt[match.start():])\n",
    "            return obj\n",
    "        except Exception:\n",
    "            continue\n",
    "    raise ValueError(\"Could not parse JSON\")\n",
    "\n",
    "def llm_json(messages: List[Dict[str, str]], temperature: float, top_p: float) -> Any:\n",
    "    \"\"\"Call LLM and parse strict JSON; one retry with 'STRICT JSON only'.\"\"\"\n",
    "    out = call_llm(messages, temperature, top_p)\n",
    "    try:\n",
    "        return parse_json_strict(out)\n",
    "    except Exception:\n",
    "        retry = messages + [{\"role\":\"user\",\"content\":\"Respond again in STRICT JSON only, no prose.\"}]\n",
    "        out2 = call_llm(retry, temperature, top_p)\n",
    "        return parse_json_strict(out2)\n",
    "\n",
    "# --------------------------- Helpers ---------------------------------\n",
    "def tfidf_embed(texts: List[str]) -> np.ndarray:\n",
    "    if not texts:\n",
    "        return np.zeros((0,0))\n",
    "    v = TfidfVectorizer(min_df=1, ngram_range=(1,2))\n",
    "    return v.fit_transform(texts).toarray()\n",
    "\n",
    "def mmr_select(items: List[str], k: int, lambda_div: float=0.65) -> List[str]:\n",
    "    \"\"\"Maximal Marginal Relevance using TF-IDF embeddings (no external models).\"\"\"\n",
    "    if not items: return []\n",
    "    if k >= len(items): return items\n",
    "    E = tfidf_embed(items)\n",
    "    if E.size == 0: return items[:k]\n",
    "    selected, candidates = [], list(range(len(items)))\n",
    "    seed_idx = max(candidates, key=lambda i: len(items[i]))  # pick the longest as seed (specificity proxy)\n",
    "    selected.append(seed_idx); candidates.remove(seed_idx)\n",
    "    while len(selected) < k and candidates:\n",
    "        sims_to_sel = cosine_similarity(E[candidates], E[selected]).max(axis=1)\n",
    "        sims_global = cosine_similarity(E[candidates], E).mean(axis=1)\n",
    "        mmr = lambda_div*(1-sims_to_sel) + (1-lambda_div)*(1-sims_global)\n",
    "        pick_rel = candidates[int(np.argmax(mmr))]\n",
    "        selected.append(pick_rel); candidates.remove(pick_rel)\n",
    "    return [items[i] for i in selected]\n",
    "\n",
    "def strip_think(x: str) -> str:\n",
    "    return re.sub(r\"</?think>\", \"\", x or \"\", flags=re.IGNORECASE).strip()\n",
    "\n",
    "# --------------------------- Phase 1: Personas -----------------------\n",
    "def generate_personas(n=N_PERSONAS) -> List[Dict[str, Any]]:\n",
    "    sys = {\"role\":\"system\",\"content\":\"You fabricate realistic civic personas. When asked for JSON, return STRICT JSON only.\"}\n",
    "    user = {\"role\":\"user\",\"content\":textwrap.dedent(f\"\"\"\n",
    "    Generate {n} civic personas as STRICT JSON under \"personas\".\n",
    "    Use a 2D ideology grid and cover all quadrants (≥1 each):\n",
    "      - Economic: left | center | right\n",
    "      - Social:   liberal | moderate | conservative\n",
    "    Add two orthogonal axes (assign one value each):\n",
    "      - Tech: skeptic | pragmatic | booster\n",
    "      - Governance: localist | federalist | market-first\n",
    "    Each persona must include:\n",
    "      - name\n",
    "      - background (1 sentence; job, place)\n",
    "      - values (4–6)\n",
    "      - expertise (array from: policy, tech, community, healthcare, law, economics, education, environment, security, faith, disability, rural_dev, transit_ops)\n",
    "      - communication_style (blunt | diplomatic | data-driven | narrative | pugilistic | legalistic | populist)\n",
    "      - priors (3 bullets that imply disagreement with another quadrant)\n",
    "      - axes: {{economic, social, tech, governance}}\n",
    "    Global constraints:\n",
    "      - Include: 1 fiscal-hawk, 1 property-rights advocate, 1 tenant-rights activist, 1 civil-liberties maximalist,\n",
    "                 1 public-safety hardliner, 1 tech-skeptic.\n",
    "      - Avoid generic language; embed concrete policy priors.\n",
    "    Return STRICT JSON only.\n",
    "    \"\"\").strip()}\n",
    "    data = llm_json([sys, user], TEMPERATURE_GEN, TOP_P_GEN)\n",
    "    personas = data[\"personas\"]\n",
    "    # display\n",
    "    pdf = pd.DataFrame([{\n",
    "        \"name\":p[\"name\"],\n",
    "        \"econ\":p.get(\"axes\",{}).get(\"economic\"),\n",
    "        \"social\":p.get(\"axes\",{}).get(\"social\"),\n",
    "        \"tech\":p.get(\"axes\",{}).get(\"tech\"),\n",
    "        \"governance\":p.get(\"axes\",{}).get(\"governance\"),\n",
    "        \"comm_style\":p.get(\"communication_style\"),\n",
    "        \"background\":p.get(\"background\")\n",
    "    } for p in personas])\n",
    "    display(pdf)\n",
    "    return personas\n",
    "\n",
    "# --------------------------- Phase 2: Topic --------------------------\n",
    "def generate_topic_and_levers() -> Dict[str, Any]:\n",
    "    sys = {\"role\":\"system\",\"content\":\"You are a neutral deliberation facilitator.\"}\n",
    "    user = {\"role\":\"user\",\"content\":textwrap.dedent(\"\"\"\n",
    "    Return STRICT JSON:\n",
    "    {\n",
    "      \"topic\": one of [congestion pricing, firearm background checks, short-term rentals, campus protest rules, fentanyl policy, zoning upzoning, police oversight boards],\n",
    "      \"phase_plan\": [\"brainstorm\",\"triage\",\"focused_deliberation\",\"reflection_and_decision\"],\n",
    "      \"prompt\": \"Neutral question forcing trade-offs (who pays, whose freedom limited, how enforced, success metric).\",\n",
    "      \"disagreement_levers\": [\"cost allocation\",\"liberty vs safety\",\"equity vs efficiency\",\"local vs federal authority\",\"surveillance vs privacy\"]\n",
    "    }\n",
    "    \"\"\").strip()}\n",
    "    tpp = llm_json([sys, user], TEMPERATURE_GEN, TOP_P_GEN)\n",
    "    topic = tpp.get(\"topic\")\n",
    "    if isinstance(topic, list) and topic:\n",
    "        tpp[\"topic\"] = topic[0]\n",
    "    prompt = tpp.get(\"prompt\")\n",
    "    if not prompt:\n",
    "        prompt = f\"What trade-offs should decision-makers weigh regarding {tpp['topic']}?\"\n",
    "        tpp[\"prompt\"] = prompt\n",
    "    display(pd.DataFrame([tpp]))\n",
    "    return tpp\n",
    "\n",
    "# --------------------------- Phase 3: Brainstorm ---------------------\n",
    "def persona_one_liner(persona: Dict[str,Any], topic: str, prompt: str, levers: List[str], prior_snippets: List[str]) -> str:\n",
    "    sys = {\"role\":\"system\",\"content\":\"Reply IN CHARACTER. EXACTLY one sentence, 18–26 words. No metadata, no XML, no <think>.\"}\n",
    "    others = \"\\n\".join(prior_snippets[-4:]) if prior_snippets else \"(none so far)\"\n",
    "    user = {\"role\":\"user\",\"content\":textwrap.dedent(f\"\"\"\n",
    "    Persona JSON:\n",
    "    {json.dumps(persona, ensure_ascii=False)}\n",
    "    Recent replies (for diversity; do NOT imitate):\n",
    "    {others}\n",
    "\n",
    "    Topic: {topic}\n",
    "    Prompt: {prompt}\n",
    "    In your sentence, touch at least one lever: {\", \".join(levers)}\n",
    "\n",
    "    Constraints:\n",
    "    - Exactly one sentence (18–26 words).\n",
    "    - Expose a concrete trade‑off tied to your axes.\n",
    "    - If your stance matches most prior replies, choose the closest justified dissent consistent with your priors.\n",
    "    \"\"\").strip()}\n",
    "    txt = call_llm([sys, user], TEMPERATURE_GEN, TOP_P_GEN)\n",
    "    return strip_think(txt)\n",
    "\n",
    "def run_brainstorm(personas: List[Dict[str,Any]], topic: str, prompt: str, levers: List[str]) -> Dict[str,str]:\n",
    "    responses, prior = {}, []\n",
    "    for p in personas:\n",
    "        resp = persona_one_liner(p, topic, prompt, levers, prior)\n",
    "        responses[p[\"name\"]] = resp\n",
    "        prior.append(f'{p[\"name\"]}: {resp}')\n",
    "    df = pd.DataFrame([{\"name\":k,\"reply\":v} for k,v in responses.items()])\n",
    "    display(df)\n",
    "    return responses\n",
    "\n",
    "# --------------------------- Phase 4: Triage -------------------------\n",
    "def extract_diverse_propositions(responses: Dict[str,str], k=K_PROPS) -> List[str]:\n",
    "    sys = {\"role\":\"system\",\"content\":\"You turn short replies into canonical policy propositions.\"}\n",
    "    joined = \"\\n\".join([f\"{k}: {v}\" for k,v in responses.items()])\n",
    "    user = {\"role\":\"user\",\"content\":textwrap.dedent(f\"\"\"\n",
    "    From these one-sentence replies:\n",
    "    {joined}\n",
    "\n",
    "    1) Propose ~{k*2} short, atomic, mutually non-overlapping propositions spanning opposed frames\n",
    "       (liberty, safety, equity, efficiency, property-rights, tenant-rights).\n",
    "    2) Then self‑prune to the most diverse {k} using a Maximal Marginal Relevance mindset (retain opposed frames).\n",
    "\n",
    "    Return STRICT JSON:\n",
    "    {{\"propositions_all\":[...], \"propositions\":[...]}}\n",
    "    \"\"\").strip()}\n",
    "    data = llm_json([sys, user], TEMPERATURE_GEN, TOP_P_GEN)\n",
    "    props = data.get(\"propositions\") or data.get(\"propositions_all\") or []\n",
    "    # Light dedup & MMR safety net\n",
    "    props = [\" \".join(p.split()) for p in props if p and p.strip()]\n",
    "    props = list(dict.fromkeys(props))  # preserve order, dedup\n",
    "    if len(props) > k:\n",
    "        props = mmr_select(props, k)\n",
    "    display(pd.DataFrame({\"proposition\":props}))\n",
    "    return props\n",
    "\n",
    "# --------------------------- Phase 5: Stance labeling ----------------\n",
    "def label_stances_scalar(persona_name: str, persona_text: str, propositions: List[str]) -> Dict[str, Dict[str, Any]]:\n",
    "    sys = {\"role\":\"system\",\"content\":\"You label stances strictly by the provided sentence. Return STRICT JSON only.\"}\n",
    "    rubric = \"\"\"\n",
    "Scale (apply strictly from the persona's sentence):\n",
    "  -2 strongly disagree: explicit rejection or opposing mechanism\n",
    "  -1 somewhat disagree: clear reservations or prefer weaker/alternative version\n",
    "   0 unsure/neutral: insufficient commitment in the sentence\n",
    "  +1 somewhat agree: support with caveat/trade-off\n",
    "  +2 strongly agree: explicit endorsement as stated\n",
    "\n",
    "Rarity rule:\n",
    "  - Use ±2 sparingly (≤ ceil(0.3 * N_props)).\n",
    "  - Prefer 0 when the sentence does not commit clearly.\n",
    "  - If violated, REVISE labels to satisfy the rule while staying faithful.\n",
    "Fields per proposition:\n",
    "  \"stance\" ∈ [-2,-1,0,1,2], \"confidence\" ∈ [0,1], \"rationale\": 3–6 words\n",
    "\"\"\"\n",
    "    user = {\"role\":\"user\",\"content\":textwrap.dedent(f\"\"\"\n",
    "    Persona response:\n",
    "    {persona_name}: {persona_text}\n",
    "\n",
    "    Apply the rubric to EACH proposition. Return STRICT JSON with:\n",
    "    {{\n",
    "      \"labels\": {{\n",
    "        \"<prop>\": {{\"stance\": INT, \"confidence\": FLOAT, \"rationale\": \"short phrase\"}},\n",
    "        ...\n",
    "      }},\n",
    "      \"extremes_used\": INT\n",
    "    }}\n",
    "    \"\"\").strip()}\n",
    "    data = llm_json([sys, {\"role\":\"user\",\"content\":rubric}, user], TEMPERATURE_LABEL, TOP_P_LABEL)\n",
    "    labels = data.get(\"labels\")\n",
    "    if not isinstance(labels, dict):\n",
    "        retry = {\"role\":\"user\",\"content\":textwrap.dedent(f\"\"\"\n",
    "        You failed to include the required JSON. For EACH proposition, provide {{\"stance\":INT,\"confidence\":FLOAT,\"rationale\":\"phrase\"}}. Re-evaluate carefully.\n",
    "        Propositions:\n",
    "        {json.dumps(propositions, ensure_ascii=False)}\n",
    "        \"\"\").strip()}\n",
    "        data = llm_json([sys, {\"role\":\"user\",\"content\":rubric}, user, retry], TEMPERATURE_LABEL, TOP_P_LABEL)\n",
    "        labels = data.get(\"labels\")\n",
    "    if not isinstance(labels, dict):\n",
    "        labels = {\n",
    "            prop: {\"stance\": 0, \"confidence\": 0.15, \"rationale\": \"insufficient signal\"}\n",
    "            for prop in propositions\n",
    "        }\n",
    "    return labels\n",
    "\n",
    "def build_matrix(personas: List[str], props: List[str], labels_by_persona: Dict[str,Dict[str,Dict[str,Any]]]) -> np.ndarray:\n",
    "    M = np.zeros((len(personas), len(props)), dtype=float)\n",
    "    for i, name in enumerate(personas):\n",
    "        labs = labels_by_persona[name]\n",
    "        for j, p in enumerate(props):\n",
    "            M[i,j] = float(labs.get(p,{}).get(\"stance\",0))\n",
    "    return M\n",
    "\n",
    "# --------------------------- Phase 6: Clustering & maps --------------\n",
    "def cluster_personas(M: np.ndarray, k=N_CLUSTERS, seed=RANDOM_SEED) -> Tuple[np.ndarray, float]:\n",
    "    if M.size == 0:\n",
    "        return np.zeros(0,dtype=int), -1.0\n",
    "    # Try KMeans, fall back to Agglomerative on cosine distances\n",
    "    try:\n",
    "        km = KMeans(n_clusters=min(k, len(M)), random_state=seed, n_init=\"auto\")\n",
    "        labels = km.fit_predict(M)\n",
    "        sil = silhouette_score(M, labels, metric=\"cosine\") if len(set(labels))>1 else -1.0\n",
    "        return labels, sil\n",
    "    except Exception:\n",
    "        D = cosine_distances(M + 1e-9)\n",
    "        agg = AgglomerativeClustering(n_clusters=min(k, len(M)), affinity=\"precomputed\", linkage=\"average\")\n",
    "        labels = agg.fit_predict(D)\n",
    "        sil = silhouette_score(M, labels, metric=\"cosine\") if len(set(labels))>1 else -1.0\n",
    "        return labels, sil\n",
    "\n",
    "def bridging_scores(M: np.ndarray, labels: np.ndarray) -> np.ndarray:\n",
    "    n_personas, n_props = M.shape\n",
    "    uniq = np.unique(labels)\n",
    "    if len(uniq) < 2:\n",
    "        return np.ones(n_props, dtype=float)\n",
    "    weights = {c: np.mean(labels==c) for c in uniq}\n",
    "    scores = np.zeros(n_props, dtype=float)\n",
    "    for j in range(n_props):\n",
    "        means = {c: M[labels==c, j].mean() for c in uniq}\n",
    "        overall = sum(weights[c]*means[c] for c in uniq)\n",
    "        penalty = sum(weights[c]*abs(means[c]-overall) for c in uniq)\n",
    "        scores[j] = max(0.0, 1.0 - (penalty/2.0))   # max gap is 2 (−2 vs +2)\n",
    "    return scores\n",
    "\n",
    "def plot_pca_scatter(M: np.ndarray, labels: np.ndarray, names: List[str]):\n",
    "    if M.shape[0] < 2: return\n",
    "    X = M if M.shape[1] < 2 else PCA(n_components=2, random_state=RANDOM_SEED).fit_transform(M)\n",
    "    plt.figure()\n",
    "    for c in sorted(set(labels)):\n",
    "        idx = np.where(labels==c)[0]\n",
    "        plt.scatter(X[idx,0], X[idx,1], label=f\"Cluster {c}\")\n",
    "    for i, n in enumerate(names):\n",
    "        plt.text(X[i,0], X[i,1], n, fontsize=8)\n",
    "    plt.title(\"Participant map (PCA over stance vectors)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_bridging(bridge: np.ndarray, props: List[str], top_n=10, title=\"Bridging scores (higher = cross-cluster overlap)\"):\n",
    "    order = np.argsort(-bridge)[:min(top_n, len(bridge))]\n",
    "    plt.figure()\n",
    "    plt.bar(range(len(order)), bridge[order])\n",
    "    plt.xticks(range(len(order)), [f\"P{int(i)+1}\" for i in order], rotation=0)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    df = pd.DataFrame({\"prop_index\":[int(i)+1 for i in order], \"bridging_score\":bridge[order], \"proposition\":[props[i] for i in order]})\n",
    "    display(df)\n",
    "\n",
    "def plot_polarizing(bridge: np.ndarray, props: List[str], top_n=10, title=\"Polarization gaps (higher = more split)\"):\n",
    "    gap = 1.0 - bridge\n",
    "    order = np.argsort(-gap)[:min(top_n, len(gap))]\n",
    "    plt.figure()\n",
    "    plt.bar(range(len(order)), gap[order])\n",
    "    plt.xticks(range(len(order)), [f\"P{int(i)+1}\" for i in order], rotation=0)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    df = pd.DataFrame({\"prop_index\":[int(i)+1 for i in order], \"gap\":gap[order], \"proposition\":[props[i] for i in order]})\n",
    "    display(df)\n",
    "\n",
    "# --------------------------- Phase 7: Focused deliberation -----------\n",
    "def propose_bridging_statements(props: List[str], bridge_scores: List[float], top_k:int=5) -> List[str]:\n",
    "    # Provide top bridging + top polarizing to LLM and ask for bridging statements\n",
    "    order_bridge = np.argsort(-np.array(bridge_scores))[:min(top_k, len(props))]\n",
    "    order_polar  = np.argsort( np.array(bridge_scores))[:min(top_k, len(props))]\n",
    "    sys = {\"role\":\"system\",\"content\":\"You are a neutral facilitator crafting bridging statements that both sides might endorse.\"}\n",
    "    user = {\"role\":\"user\",\"content\":textwrap.dedent(f\"\"\"\n",
    "    Given these propositions (index, text) and their bridging scores (0..1, higher is more cross-cluster overlap):\n",
    "\n",
    "    TOP BRIDGING:\n",
    "    {json.dumps([{ \"index\":int(i)+1, \"prop\":props[i], \"bridging\":float(bridge_scores[i]) } for i in order_bridge], ensure_ascii=False, indent=2)}\n",
    "\n",
    "    MOST POLARIZING:\n",
    "    {json.dumps([{ \"index\":int(i)+1, \"prop\":props[i], \"bridging\":float(bridge_scores[i]) } for i in order_polar], ensure_ascii=False, indent=2)}\n",
    "\n",
    "    Task:\n",
    "    - Propose 5 concise BRIDGING STATEMENTS (one sentence each) that preserve core policy content but adjust framing to improve cross-cluster support.\n",
    "    - Vary frames (liberty, safety, equity, efficiency, property-rights, tenant-rights).\n",
    "    Return STRICT JSON: {{\"bridges\":[ \"...\", \"...\", \"...\", \"...\", \"...\" ]}}\n",
    "    \"\"\").strip()}\n",
    "    data = llm_json([sys, user], TEMPERATURE_GEN, TOP_P_GEN)\n",
    "    bridges = [strip_think(s) for s in data.get(\"bridges\", []) if s and s.strip()]\n",
    "    display(pd.DataFrame({\"bridging_statement\":bridges}))\n",
    "    return bridges\n",
    "\n",
    "# --------------------------- Phase 8: Reflection & decision ----------\n",
    "def summarize_and_decide(M: np.ndarray, labels: np.ndarray, props: List[str], bridge: np.ndarray):\n",
    "    # Simple reflection: report cluster means and suggest top 3 bridging props as \"recommendations\"\n",
    "    uniq = sorted(set(labels))\n",
    "    centroids = [M[labels==c].mean(axis=0) for c in uniq]\n",
    "    cent_df = pd.DataFrame(centroids, columns=[f\"P{j+1}\" for j in range(len(props))])\n",
    "    cent_df.insert(0, \"cluster\", uniq)\n",
    "    display(cent_df)\n",
    "    # Recommendations: top-3 bridging props\n",
    "    order = list(np.argsort(-bridge)[:min(3, len(bridge))])\n",
    "    recs = [{\"rank\":i+1,\"prop_index\":int(j)+1,\"proposition\":props[j],\"bridging_score\":float(bridge[j])} for i,j in enumerate(order)]\n",
    "    display(pd.DataFrame(recs))\n",
    "\n",
    "# --------------------------- Orchestration ---------------------------\n",
    "def run_pipeline():\n",
    "    print(\"=== Phase 1: Personas ===\")\n",
    "    personas = generate_personas(N_PERSONAS)\n",
    "\n",
    "    print(\"\\n=== Phase 2: Topic & Levers ===\")\n",
    "    tpp = generate_topic_and_levers()\n",
    "    topic, prompt = tpp[\"topic\"], tpp[\"prompt\"]\n",
    "    levers = tpp.get(\"disagreement_levers\", [])\n",
    "\n",
    "    print(\"\\n=== Phase 3: Brainstorm (one-liners) ===\")\n",
    "    responses = run_brainstorm(personas, topic, prompt, levers)\n",
    "\n",
    "    print(\"\\n=== Phase 4: Triage (propositions) ===\")\n",
    "    props = extract_diverse_propositions(responses, K_PROPS)\n",
    "\n",
    "    print(\"\\n=== Phase 5: Stance labeling ([-2..+2]) ===\")\n",
    "    persona_names = [p[\"name\"] for p in personas]\n",
    "    labels_by_persona = {}\n",
    "    for p in persona_names:\n",
    "        labels_by_persona[p] = label_stances_scalar(p, responses[p], props)\n",
    "    # Tabulate stance matrix\n",
    "    M = build_matrix(persona_names, props, labels_by_persona)\n",
    "    dfM = pd.DataFrame(M, index=persona_names, columns=[f\"P{j+1}\" for j in range(len(props))])\n",
    "    display(dfM)\n",
    "\n",
    "    print(\"\\n=== Phase 6: Clustering & maps ===\")\n",
    "    labels, sil = cluster_personas(M, k=N_CLUSTERS, seed=RANDOM_SEED)\n",
    "    dfC = pd.DataFrame({\"name\":persona_names, \"cluster\":labels})\n",
    "    display(dfC.sort_values(\"cluster\"))\n",
    "    print(f\"Silhouette (cosine): {sil:.3f}\")\n",
    "    plot_pca_scatter(M, labels, persona_names)\n",
    "\n",
    "    bridge = bridging_scores(M, labels)\n",
    "    plot_bridging(bridge, props, top_n=min(10,len(props)))\n",
    "    plot_polarizing(bridge, props, top_n=min(10,len(props)))\n",
    "\n",
    "    print(\"\\n=== Phase 7: Focused deliberation (bridging statements) ===\")\n",
    "    bridges = propose_bridging_statements(props, bridge, top_k=5)\n",
    "\n",
    "    print(\"\\n=== Phase 8: Reflection & decision ===\")\n",
    "    summarize_and_decide(M, labels, props, bridge)\n",
    "    print(\"\\nDone.\")\n",
    "\n",
    "# --------------------------- Run ------------------------------------\n",
    "run_pipeline()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0129a0c4-a4b9-4407-bc20-eddd12938a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
