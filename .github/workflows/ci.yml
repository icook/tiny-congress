name: CI

on:
  push:
    branches:
      - master
  pull_request:
    branches:
      - '**'

concurrency:
  group: ${{ github.workflow }}-${{ github.event.number || github.sha }}
  cancel-in-progress: true

env:
  REGISTRY: ghcr.io/${{ github.repository }}

jobs:
  # ============================================================
  # JOB 0: Lint Rust formatting
  # ============================================================
  lint:
    name: Lint Rust formatting
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy

      - name: Check formatting
        working-directory: service
        run: cargo fmt --all -- --check

      - name: Clippy
        working-directory: service
        run: |
          # Dev-only tooling pulls in unstable deps (e.g., cargo-llvm-cov via ruzstd),
          # so keep clippy scoped to library and binaries.
          cargo clippy --all-features -- -D warnings

  # ============================================================
  # JOB 0b: Lint web
  # ============================================================
  lint-web:
    name: Lint web
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Node
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: yarn
          cache-dependency-path: web/yarn.lock

      - name: Enable corepack
        run: corepack enable

      - name: Install dependencies
        working-directory: web
        run: yarn install --immutable

      - name: Run Linters
        working-directory: web
        run: yarn lint

  # ============================================================
  # JOB 1: Build all container images in parallel
  # ============================================================
  build-images:
    name: Build ${{ matrix.image }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    strategy:
      fail-fast: false
      matrix:
        include:
          - image: tc-api-release
            context: ./service
            dockerfile: service/Dockerfile
          - image: tc-ui-release
            context: ./web
            dockerfile: web/Dockerfile
          - image: postgres
            context: .
            dockerfile: dockerfiles/Dockerfile.postgres
    outputs:
      tc-api-release-tag: ${{ steps.meta.outputs.tc-api-release-tag }}
      tc-ui-release-tag: ${{ steps.meta.outputs.tc-ui-release-tag }}
      postgres-tag: ${{ steps.meta.outputs.postgres-tag }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Compute tags
        id: tags
        run: |
          ref="${GITHUB_HEAD_REF:-$GITHUB_REF_NAME}"
          branch="${ref//[^a-zA-Z0-9_.-]/-}"
          branch="${branch,,}"
          echo "branch_slug=${branch}" >> "$GITHUB_OUTPUT"
          echo "sha_tag=${{ env.REGISTRY }}/${{ matrix.image }}:${{ github.sha }}" >> "$GITHUB_OUTPUT"
          echo "branch_tag=${{ env.REGISTRY }}/${{ matrix.image }}:branch-${branch}" >> "$GITHUB_OUTPUT"

      - name: Build and push ${{ matrix.image }}
        uses: docker/build-push-action@v6
        with:
          context: ${{ matrix.context }}
          file: ${{ matrix.dockerfile }}
          push: true
          platforms: linux/amd64
          build-args: |
            BUILDKIT_INLINE_CACHE=1
          tags: |
            ${{ steps.tags.outputs.sha_tag }}
            ${{ steps.tags.outputs.branch_tag }}
          cache-from: |
            type=gha,scope=${{ matrix.image }}
            type=registry,ref=${{ env.REGISTRY }}/${{ matrix.image }}:cache
          cache-to: |
            type=gha,scope=${{ matrix.image }},mode=max
            type=registry,ref=${{ env.REGISTRY }}/${{ matrix.image }}:cache,mode=max

      - name: Export image metadata
        id: meta
        run: |
          echo "${{ matrix.image }}-tag=${{ steps.tags.outputs.sha_tag }}" >> "$GITHUB_OUTPUT"

  # ============================================================
  # JOB 2: Aggregate image metadata from matrix
  # ============================================================
  collect-image-metadata:
    name: Collect image metadata
    runs-on: ubuntu-latest
    needs: build-images
    outputs:
      artifacts_json: ${{ steps.generate.outputs.artifacts_json }}
    steps:
      - name: Generate Skaffold artifacts JSON
        id: generate
        run: |
          artifacts=$(cat <<'EOF'
          {
            "builds": [
              {"imageName": "tc-api-release", "tag": "${{ env.REGISTRY }}/tc-api-release:${{ github.sha }}"},
              {"imageName": "tc-ui-release", "tag": "${{ env.REGISTRY }}/tc-ui-release:${{ github.sha }}"},
              {"imageName": "postgres", "tag": "${{ env.REGISTRY }}/postgres:${{ github.sha }}"}
            ]
          }
          EOF
          )
          artifacts_escaped=$(echo "$artifacts" | jq -c .)
          echo "artifacts_json=${artifacts_escaped}" >> "$GITHUB_OUTPUT"
        env:
          REGISTRY: ghcr.io/${{ github.repository }}

  # ============================================================
  # JOB 3: Run Skaffold test/deploy and host-based integration/E2E tests
  # ============================================================
  test-and-deploy:
    name: Integration tests
    runs-on: ubuntu-latest
    needs:
      - collect-image-metadata
      - lint
      - lint-web
    permissions:
      contents: read
      packages: read
      checks: write
    env:
      SKAFFOLD_DEFAULT_REPO: ghcr.io/${{ github.repository }}
      SKAFFOLD_PROFILE: ci
      PLAYWRIGHT_BROWSERS_PATH: ${{ github.workspace }}/.cache/ms-playwright
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install KinD tooling
        uses: helm/kind-action@v1.13.0
        with:
          install_only: true
          cluster_name: skaffold-ci

      - name: Start KinD cluster in background
        run: |
          set -euo pipefail
          KIND_LOG="${RUNNER_TEMP}/kind.log"

          echo "KIND_LOG=${KIND_LOG}" >> "$GITHUB_ENV"

          echo "Starting KinD cluster skaffold-ci (logs: ${KIND_LOG})"
          kind create cluster --name skaffold-ci --wait 0s >"${KIND_LOG}" 2>&1 &

      - name: Cache Skaffold
        id: cache-skaffold
        uses: actions/cache@v4
        with:
          path: /usr/local/bin/skaffold
          key: skaffold-v2.17.0

      - name: Install Skaffold
        if: steps.cache-skaffold.outputs.cache-hit != 'true'
        run: |
          set -euo pipefail
          SKAFFOLD_VERSION=v2.16.1
          curl -fsSL -o skaffold https://storage.googleapis.com/skaffold/releases/${SKAFFOLD_VERSION}/skaffold-linux-amd64
          sudo install skaffold /usr/local/bin/skaffold

      - name: Verify Skaffold installation
        run: skaffold version

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Write Skaffold artifacts file
        id: artifacts
        run: |
          set -euo pipefail
          artifacts_file="${RUNNER_TEMP}/skaffold-artifacts.json"
          echo '${{ needs.collect-image-metadata.outputs.artifacts_json }}' > "$artifacts_file"
          echo "Artifacts file contents:"
          cat "$artifacts_file"
          echo "file=${artifacts_file}" >> "$GITHUB_OUTPUT"

      - name: Set up Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          components: llvm-tools-preview

      - name: Install cargo-llvm-cov
        uses: taiki-e/install-action@cargo-llvm-cov

      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@v2
        with:
          workspaces: service -> target

      - name: Set up Node
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: yarn
          cache-dependency-path: web/yarn.lock

      - name: Enable corepack
        run: corepack enable

      - name: Install web dependencies
        working-directory: web
        run: yarn install --immutable

      - name: Cache Playwright browsers
        id: cache-playwright
        uses: actions/cache@v4
        with:
          path: ${{ env.PLAYWRIGHT_BROWSERS_PATH }}
          key: playwright-${{ runner.os }}-${{ hashFiles('web/yarn.lock') }}

      - name: Install Playwright browsers
        working-directory: web
        run: yarn playwright install --with-deps chromium

      - name: Prepare test output directories
        run: |
          mkdir -p web/reports web/test-results web/coverage/playwright service/coverage
          rm -f service/coverage/backend-unit.lcov service/coverage/backend-integration.lcov

      - name: Run Skaffold tests
        run: |
          set -euo pipefail
          skaffold test -p ${SKAFFOLD_PROFILE} --build-artifacts "${{ steps.artifacts.outputs.file }}"

      - name: Wait for KinD readiness
        run: |
          set -euo pipefail
          : "${KIND_LOG:?KIND_LOG not set}"
          echo "Waiting for cluster API to become available..."
          if ! timeout 180 bash -c 'until kubectl cluster-info --context kind-skaffold-ci >/dev/null 2>&1; do sleep 5; done'; then
            echo "KinD did not finish starting in time; dumping logs."
            cat "${KIND_LOG}" || true
            exit 1
          fi
          kubectl version --client=true
          kubectl cluster-info
          kubectl get nodes -o wide

      - name: Configure registry access for KinD
        run: |
          set -euo pipefail
          kubectl create secret docker-registry ghcr-cred \
            --namespace default \
            --docker-server=ghcr.io \
            --docker-username="${{ github.actor }}" \
            --docker-password="${{ secrets.GITHUB_TOKEN }}" \
            --dry-run=client -o yaml | kubectl apply -f -

          kubectl patch serviceaccount default \
            -n default \
            --type merge \
            -p '{"imagePullSecrets":[{"name":"ghcr-cred"}]}'

      - name: Deploy with Skaffold
        run: |
          set -euo pipefail
          skaffold deploy -p ${SKAFFOLD_PROFILE} --status-check=true --build-artifacts "${{ steps.artifacts.outputs.file }}"

      - name: Run Rust integration tests
        run: |
          set -euo pipefail
          # Ensure Postgres is ready before port-forwarding
          kubectl wait --for=condition=available --timeout=180s deployment/postgres

          # Port-forward PostgreSQL
          kubectl port-forward svc/postgres 5432:5432 &
          PF_PG_PID=$!

          # Run integration tests
          cd service
          DATABASE_URL=postgres://postgres:postgres@localhost:5432/prioritization \
            ARTIFACTS_DIR=coverage \
            ./bin/integration-coverage.sh

          # Cleanup
          kill $PF_PG_PID 2>/dev/null || true

      - name: Run Playwright E2E tests
        run: |
          set -euo pipefail
          # Port-forward frontend
          kubectl port-forward deployment/tc-frontend 5173:80 &
          PF_FRONTEND_PID=$!
          timeout 60 bash -c 'until curl -sf http://localhost:5173 > /dev/null; do sleep 1; done'

          # Run Playwright tests
          cd web
          node ./scripts/reset-playwright-coverage.mjs
          CI=true PLAYWRIGHT_BASE_URL=http://localhost:5173 PLAYWRIGHT_COVERAGE=1 yarn playwright:test || TEST_EXIT=$?
          if [ -d .nyc_output ]; then
            yarn playwright:report || true
          fi

          # Cleanup
          kill $PF_FRONTEND_PID 2>/dev/null || true
          exit ${TEST_EXIT:-0}

      - name: Publish Playwright test report
        if: always() && hashFiles('web/reports/playwright.xml') != ''
        uses: EnricoMi/publish-unit-test-result-action@v2
        with:
          files: web/reports/playwright.xml
          report_individual_runs: true
          check_name: Playwright E2E
          comment_mode: off

      - name: Upload Playwright coverage
        if: always() && hashFiles('web/coverage/playwright/lcov.info') != ''
        uses: actions/upload-artifact@v4
        with:
          name: playwright-coverage
          path: web/coverage/playwright/lcov.info

      - name: Summarize Playwright coverage
        if: always() && hashFiles('web/coverage/playwright/coverage-summary.json') != ''
        run: |
          node - <<'EOF'
          import fs from 'node:fs';
          import path from 'node:path';

          const summaryPath = path.join(process.cwd(), 'web/coverage/playwright/coverage-summary.json');
          const summary = JSON.parse(fs.readFileSync(summaryPath, 'utf8')).total;
          const rows = [
            ['Lines', `${summary.lines.pct}%`, summary.lines.covered, summary.lines.total],
            ['Statements', `${summary.statements.pct}%`, summary.statements.covered, summary.statements.total],
            ['Functions', `${summary.functions.pct}%`, summary.functions.covered, summary.functions.total],
            ['Branches', `${summary.branches.pct}%`, summary.branches.covered, summary.branches.total],
          ].map((cells) => `| ${cells.join(' | ')} |`).join('\n');

          const header = '| Metric | Pct | Covered | Total |';
          const separator = '| --- | --- | --- | --- |';
          const body = `### Playwright coverage\n${header}\n${separator}\n${rows}\n`;
          fs.appendFileSync(process.env.GITHUB_STEP_SUMMARY, body);
          EOF

      - name: Upload Playwright artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-artifacts
          if-no-files-found: warn
          path: |
            web/test-results
            web/reports/playwright.xml
            web/coverage/playwright

      - name: Upload Rust coverage artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: rust-coverage
          if-no-files-found: warn
          path: |
            service/coverage/backend-unit.lcov
            service/coverage/backend-integration.lcov

      - name: Summarize Rust coverage
        if: always()
        run: |
          python - <<'PY'
          import os
          import pathlib

          summary_file = os.environ.get("GITHUB_STEP_SUMMARY")

          paths = [
              pathlib.Path("service/coverage/backend-unit.lcov"),
              pathlib.Path("service/coverage/backend-integration.lcov"),
          ]

          def parse_lcov(path: pathlib.Path):
              total = 0
              covered = 0
              if not path.exists():
                  return total, covered
              with path.open() as fh:
                  for line in fh:
                      if not line.startswith("DA:"):
                          continue
                      try:
                          _, payload = line.strip().split(":", 1)
                          line_no, count = payload.split(",", 1)
                          count = int(count)
                      except ValueError:
                          continue
                      total += 1
                      if count > 0:
                          covered += 1
              return total, covered

          def combine_unique(paths):
              # Track unique file+line across all suites
              seen = {}
              for path in paths:
                  if not path.exists():
                      continue
                  current_file = None
                  with path.open() as fh:
                      for line in fh:
                          if line.startswith("SF:"):
                              current_file = line.strip()[3:]
                              continue
                          if not line.startswith("DA:") or current_file is None:
                              continue
                          try:
                              _, payload = line.strip().split(":", 1)
                              line_no, count = payload.split(",", 1)
                              count = int(count)
                              line_no = int(line_no)
                          except ValueError:
                              continue
                          key = (current_file, line_no)
                          seen[key] = seen.get(key, False) or count > 0
              total = len(seen)
              covered = sum(1 for covered_line in seen.values() if covered_line)
              return total, covered

          rows = []
          for path in paths:
              total, covered = parse_lcov(path)
              pct = (covered / total * 100) if total else 0.0
              rows.append((path.stem, pct, covered, total))

          combined_total, combined_covered = combine_unique(paths)
          combined_pct = (combined_covered / combined_total * 100) if combined_total else 0.0

          lines = []
          lines.append("### Rust coverage")
          lines.append("| Suite | Pct | Covered | Total |")
          lines.append("| --- | --- | --- | --- |")
          for name, pct, covered, total in rows:
              lines.append(f"| {name} | {pct:.2f}% | {covered} | {total} |")
          lines.append(f"| combined | {combined_pct:.2f}% | {combined_covered} | {combined_total} |")

          output = "\n".join(lines) + "\n"

          if summary_file:
              with open(summary_file, "a", encoding="utf-8") as fh:
                  fh.write(output)
          else:
              print(output)
          PY

      - name: Dump diagnostics on failure
        if: failure()
        run: |
          echo '--- Pods ---'
          kubectl get pods -A -o wide || true
          echo '--- Services ---'
          kubectl get svc -A || true
          echo '--- Events ---'
          kubectl get events -A --sort-by=.lastTimestamp || true
          echo '--- All Resources ---'
          kubectl get all -n default || true

  # ============================================================
  # JOB 4: Build production images after verification
  # ============================================================
  build-release-images:
    name: Build release ${{ matrix.image }}
    needs:
      - skaffold-verify
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    strategy:
      fail-fast: false
      matrix:
        include:
          - image: tc-api-release
            context: ./service
            dockerfile: service/Dockerfile
          - image: tc-ui-release
            context: ./web
            dockerfile: web/Dockerfile
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Compute tags
        id: tags
        run: |
          ref="${GITHUB_HEAD_REF:-$GITHUB_REF_NAME}"
          branch="${ref//[^a-zA-Z0-9_.-]/-}"
          branch="${branch,,}"
          echo "branch_slug=${branch}" >> "$GITHUB_OUTPUT"
          echo "sha_tag=${{ env.REGISTRY }}/${{ matrix.image }}:${{ github.sha }}" >> "$GITHUB_OUTPUT"
          echo "branch_tag=${{ env.REGISTRY }}/${{ matrix.image }}:branch-${branch}" >> "$GITHUB_OUTPUT"

      - name: Build and push ${{ matrix.image }}
        uses: docker/build-push-action@v6
        with:
          context: ${{ matrix.context }}
          file: ${{ matrix.dockerfile }}
          push: true
          platforms: linux/amd64
          build-args: |
            BUILDKIT_INLINE_CACHE=1
          tags: |
            ${{ steps.tags.outputs.sha_tag }}
            ${{ steps.tags.outputs.branch_tag }}
          cache-from: |
            type=gha,scope=${{ matrix.image }}
            type=registry,ref=${{ env.REGISTRY }}/${{ matrix.image }}:cache
          cache-to: |
            type=gha,scope=${{ matrix.image }},mode=max
            type=registry,ref=${{ env.REGISTRY }}/${{ matrix.image }}:cache,mode=max
